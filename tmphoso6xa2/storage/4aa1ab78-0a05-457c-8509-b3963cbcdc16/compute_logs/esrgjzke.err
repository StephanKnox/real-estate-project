[32m2023-05-31 12:37:42 +0200[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - 4aa1ab78-0a05-457c-8509-b3963cbcdc16 - 56326 - LOGS_CAPTURED - Started capturing logs in process (pid: 56326).
[32m2023-05-31 12:37:42 +0200[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - 4aa1ab78-0a05-457c-8509-b3963cbcdc16 - 56326 - create_delta_table - STEP_START - Started execution of step "create_delta_table".
Ivy Default Cache set to: /Users/ctac/.ivy2/cache
The jars for the packages stored in: /Users/ctac/.ivy2/jars
io.delta#delta-core_2.12 added as a dependency
org.apache.hadoop#hadoop-aws added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-6a6c0a61-0365-4085-af41-eb8230c820c2;1.0
	confs: [default]
	found io.delta#delta-core_2.12;2.1.0 in central
	found io.delta#delta-storage;2.1.0 in central
	found org.antlr#antlr4-runtime;4.8 in central
	found org.codehaus.jackson#jackson-core-asl;1.9.13 in central
	found org.apache.hadoop#hadoop-aws;3.3.2 in central
	found com.amazonaws#aws-java-sdk-bundle;1.11.1026 in central
	found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central
:: resolution report :: resolve 129ms :: artifacts dl 7ms
	:: modules in use:
	com.amazonaws#aws-java-sdk-bundle;1.11.1026 from central in [default]
	io.delta#delta-core_2.12;2.1.0 from central in [default]
	io.delta#delta-storage;2.1.0 from central in [default]
	org.antlr#antlr4-runtime;4.8 from central in [default]
	org.apache.hadoop#hadoop-aws;3.3.2 from central in [default]
	org.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]
	org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   7   |   0   |   0   |   0   ||   7   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-6a6c0a61-0365-4085-af41-eb8230c820c2
	confs: [default]
	0 artifacts copied, 7 already retrieved (0kB/4ms)
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[32m2023-05-31 12:37:47 +0200[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - 4aa1ab78-0a05-457c-8509-b3963cbcdc16 - 56326 - create_delta_table - LOADED_INPUT - Loaded input "json_to_flat_properties" using input manager "local_parquet_io_manager"
[32m2023-05-31 12:37:47 +0200[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - 4aa1ab78-0a05-457c-8509-b3963cbcdc16 - 56326 - create_delta_table - STEP_INPUT - Got input "json_to_flat_properties" of type "DataFrame". (Type check passed).
[32m2023-05-31 12:37:48 +0200[0m - dagster - [34mINFO[0m - __ASSET_JOB - 4aa1ab78-0a05-457c-8509-b3963cbcdc16 - create_delta_table - 19344
[Stage 4:>                                                          (0 + 8) / 8][Stage 4:===================================================>       (7 + 1) / 8]                                                                                [Stage 7:==============================================>          (41 + 8) / 50]                                                                                [32m2023-05-31 12:37:56 +0200[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - 4aa1ab78-0a05-457c-8509-b3963cbcdc16 - 56326 - create_delta_table - STEP_OUTPUT - Yielded output "result" of type "Any". (Type check passed).
[32m2023-05-31 12:37:56 +0200[0m - dagster - [34mERROR[0m - [31m__ASSET_JOB - 4aa1ab78-0a05-457c-8509-b3963cbcdc16 - 56326 - create_delta_table - STEP_FAILURE - Execution of step "create_delta_table" failed.

dagster._core.errors.DagsterExecutionHandleOutputError: Error occurred while handling output "result" of step "create_delta_table"::

AttributeError: 'NoneType' object has no attribute 'write'

Stack Trace:
  File "/Users/ctac/Desktop/Data Engineer /Projects/realestate_scraping_project/env/lib/python3.11/site-packages/dagster/_core/execution/plan/utils.py", line 54, in op_execution_error_boundary
    yield
  File "/Users/ctac/Desktop/Data Engineer /Projects/realestate_scraping_project/env/lib/python3.11/site-packages/dagster/_utils/__init__.py", line 443, in iterate_with_context
    next_output = next(iterator)
                  ^^^^^^^^^^^^^^
  File "/Users/ctac/Desktop/Data Engineer /Projects/realestate_scraping_project/env/lib/python3.11/site-packages/dagster/_core/execution/plan/execute_step.py", line 591, in _gen_fn
    gen_output = output_manager.handle_output(output_context, output.value)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctac/Desktop/Data Engineer /Projects/realestate_scraping_project/realestate-scraping/realestate_scraping/__init__.py", line 142, in handle_output
    obj.write.mode("overwrite").parquet('./data')
    ^^^^^^^^^
[0m
