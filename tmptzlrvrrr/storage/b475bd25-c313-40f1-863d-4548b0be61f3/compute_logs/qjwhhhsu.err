[32m2023-05-31 17:06:25 +0200[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - b475bd25-c313-40f1-863d-4548b0be61f3 - 64898 - LOGS_CAPTURED - Started capturing logs in process (pid: 64898).
[32m2023-05-31 17:06:25 +0200[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - b475bd25-c313-40f1-863d-4548b0be61f3 - 64898 - filter_for_new_properties - STEP_START - Started execution of step "filter_for_new_properties".
[32m2023-05-31 17:06:25 +0200[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - b475bd25-c313-40f1-863d-4548b0be61f3 - filter_for_new_properties - Loading file from: /Users/ctac/Desktop/Data Engineer /Projects/realestate_scraping_project/realestate-scraping/tmptzlrvrrr/storage/scrape_pages
[32m2023-05-31 17:06:25 +0200[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - b475bd25-c313-40f1-863d-4548b0be61f3 - 64898 - filter_for_new_properties - ASSET_OBSERVATION - DagsterEventType.ASSET_OBSERVATION for step filter_for_new_properties
[32m2023-05-31 17:06:25 +0200[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - b475bd25-c313-40f1-863d-4548b0be61f3 - 64898 - filter_for_new_properties - LOADED_INPUT - Loaded input "scrape_pages" using input manager "io_manager"
[32m2023-05-31 17:06:25 +0200[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - b475bd25-c313-40f1-863d-4548b0be61f3 - 64898 - filter_for_new_properties - STEP_INPUT - Got input "scrape_pages" of type "Any". (Type check passed).
[32m2023-05-31 17:06:25 +0200[0m - dagster - [34mINFO[0m - __ASSET_JOB - b475bd25-c313-40f1-863d-4548b0be61f3 - filter_for_new_properties - 7690922, 7635457, 7559068, 7559066, 7559065, 7727366, 7709765, 7578309, 7338541, 7772664, 7735830, 7720425, 7647599, 7639122, 7623880, 7613298, 7474666, 7474665, 7406184, 7225881, 7745445, 7702297, 7698213, 7527881, 7709306, 7695206, 7590507, 7522758, 7784310, 7719378, 7703774, 7691072, 7647922, 7574202, 7573317, 7230162, 7771051, 7768739, 7711858, 7559067, 7495182, 7786651, 7779868, 7777242, 7767549, 7764133, 7747674, 7740255, 7485074, 7782231, 7779706, 7776745, 7770357, 7764936, 7751534, 7709465, 7646624, 7548945, 7485072, 7789762, 7775070, 7773772, 7756265, 7756264, 7756261, 7782147, 7775487, 7773803, 7773802, 7749271, 7747420, 7746453, 7782500, 7762980, 7536330, 7789302, 7777241, 7711210, 7636044, 7784119, 7781730, 7781725, 7773943, 7766016, 7765656, 7765444, 7761850, 7755498, 7750480, 7748976, 7718368, 7704435, 7685814, 7635915, 7635870, 7600725, 7383673, 7608971, 7525705, 7317300, 7573080, 7787767, 7773700, 7760655, 7780751, 7777312, 7787419, 7784913, 7714320, 7779836, 7747509, 7652592, 7506653, 7745046, 7326682, 7789763, 7786759, 7759653, 7744944, 7788731, 7375633, 7326599, 7696577, 7668256, 7556324, 7603202, 7433654, 7388749, 7388748, 7744100, 7727179, 7484912, 7456052, 7403304, 7579835, 7449562, 7333221, 7603446, 7363883, 7313175, 7313168, 7308985, 7772372, 7713243
Ivy Default Cache set to: /Users/ctac/.ivy2/cache
The jars for the packages stored in: /Users/ctac/.ivy2/jars
io.delta#delta-core_2.12 added as a dependency
org.apache.hadoop#hadoop-aws added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-b2b74ba2-428b-43a4-accc-efc3430c0a3e;1.0
	confs: [default]
	found io.delta#delta-core_2.12;2.1.0 in central
	found io.delta#delta-storage;2.1.0 in central
	found org.antlr#antlr4-runtime;4.8 in central
	found org.codehaus.jackson#jackson-core-asl;1.9.13 in central
	found org.apache.hadoop#hadoop-aws;3.3.2 in central
	found com.amazonaws#aws-java-sdk-bundle;1.11.1026 in central
	found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central
:: resolution report :: resolve 122ms :: artifacts dl 5ms
	:: modules in use:
	com.amazonaws#aws-java-sdk-bundle;1.11.1026 from central in [default]
	io.delta#delta-core_2.12;2.1.0 from central in [default]
	io.delta#delta-storage;2.1.0 from central in [default]
	org.antlr#antlr4-runtime;4.8 from central in [default]
	org.apache.hadoop#hadoop-aws;3.3.2 from central in [default]
	org.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]
	org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   7   |   0   |   0   |   0   ||   7   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-b2b74ba2-428b-43a4-accc-efc3430c0a3e
	confs: [default]
	0 artifacts copied, 7 already retrieved (0kB/3ms)
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[32m2023-05-31 17:06:29 +0200[0m - dagster - [34mINFO[0m - __ASSET_JOB - b475bd25-c313-40f1-863d-4548b0be61f3 - filter_for_new_properties -           id      fingerprint     city
0    7690922  7690922-1295000  zuerich
1    7635457  7635457-1475000  zuerich
2    7559068  7559068-1760000  zuerich
3    7559066  7559066-2100000  zuerich
4    7559065  7559065-1630000  zuerich
..       ...              ...      ...
139  7313175  7313175-2290000  zuerich
140  7313168  7313168-2980000  zuerich
141  7308985  7308985-2680000  zuerich
142  7772372   7772372-499000  zuerich
143  7713243  7713243-3600000  zuerich

[144 rows x 3 columns]
[Stage 2:=========>                                                (8 + 8) / 50][Stage 2:=========================>                               (22 + 8) / 50][Stage 2:============================================>            (39 + 8) / 50]                                                                                [Stage 8:>                                                          (0 + 8) / 8]                                                                                [32m2023-05-31 17:06:37 +0200[0m - dagster - [34mERROR[0m - [31m__ASSET_JOB - b475bd25-c313-40f1-863d-4548b0be61f3 - 64898 - filter_for_new_properties - STEP_FAILURE - Execution of step "filter_for_new_properties" failed.

dagster._core.errors.DagsterExecutionStepExecutionError: Error occurred while executing op "filter_for_new_properties"::

AttributeError: 'DataFrame' object has no attribute 'select'

Stack Trace:
  File "/Users/ctac/Desktop/Data Engineer /Projects/realestate_scraping_project/env/lib/python3.11/site-packages/dagster/_core/execution/plan/utils.py", line 54, in op_execution_error_boundary
    yield
  File "/Users/ctac/Desktop/Data Engineer /Projects/realestate_scraping_project/env/lib/python3.11/site-packages/dagster/_utils/__init__.py", line 443, in iterate_with_context
    next_output = next(iterator)
                  ^^^^^^^^^^^^^^
  File "/Users/ctac/Desktop/Data Engineer /Projects/realestate_scraping_project/env/lib/python3.11/site-packages/dagster/_core/execution/plan/compute_generator.py", line 124, in _coerce_solid_compute_fn_to_iterator
    result = invoke_compute_fn(
             ^^^^^^^^^^^^^^^^^^
  File "/Users/ctac/Desktop/Data Engineer /Projects/realestate_scraping_project/env/lib/python3.11/site-packages/dagster/_core/execution/plan/compute_generator.py", line 118, in invoke_compute_fn
    return fn(context, **args_to_pass) if context_arg_provided else fn(**args_to_pass)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctac/Desktop/Data Engineer /Projects/realestate_scraping_project/realestate-scraping/realestate_scraping/assets/core/realestate_scraping.py", line 144, in filter_for_new_properties
    context.log.info(f"Existing properties: {pd_existing_props.select('*')}")
                                             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ctac/Desktop/Data Engineer /Projects/realestate_scraping_project/env/lib/python3.11/site-packages/pandas/core/generic.py", line 5989, in __getattr__
    return object.__getattribute__(self, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0m
